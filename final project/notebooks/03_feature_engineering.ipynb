{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7853351-570c-42a1-a292-337cbb2c95f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9309, 6), (458, 6))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"../data/train_final.csv\")\n",
    "df_test  = pd.read_csv(\"../data/test_final.csv\")\n",
    "\n",
    "df_train.shape, df_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfe84c9-35cf-41af-a9f1-20dd65338727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7053b77a-df04-447e-bfc0-b721538acde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns that form the problem statement\n",
    "TEXT_COLUMNS = [\"title\", \"description\", \"input_format\", \"output_format\"]\n",
    "\n",
    "# Safety: replace missing values with empty strings\n",
    "for col in TEXT_COLUMNS:\n",
    "    df_train[col] = df_train[col].fillna(\"\")\n",
    "    df_test[col] = df_test[col].fillna(\"\")\n",
    "\n",
    "# Create combined text\n",
    "df_train[\"combined_text\"] = (\n",
    "    df_train[\"title\"] + \" \" +\n",
    "    df_train[\"description\"] + \" \" +\n",
    "    df_train[\"input_format\"] + \" \" +\n",
    "    df_train[\"output_format\"]\n",
    ")\n",
    "\n",
    "df_test[\"combined_text\"] = (\n",
    "    df_test[\"title\"] + \" \" +\n",
    "    df_test[\"description\"] + \" \" +\n",
    "    df_test[\"input_format\"] + \" \" +\n",
    "    df_test[\"output_format\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c0853dd-9e4e-4d34-b87a-cb24607d6fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"] = df_train[\"combined_text\"].apply(clean_text)\n",
    "df_test[\"clean_text\"] = df_test[\"combined_text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f5be6a8-7401-46ad-a067-bb71696cc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e338462-ad99-40c8-bfb0-4bda29e87200",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = vectorizer.fit_transform(df_train[\"clean_text\"])\n",
    "X_test_tfidf = vectorizer.transform(df_test[\"clean_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9792834-d247-4cb8-9583-2b64bbaa4c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9309, 5000), (458, 5000))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape, X_test_tfidf.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221a6b68-cb96-4689-bf5f-d1bc12599eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(vectorizer, \"../models/tfidf_vectorizer.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45768753-0c18-46f2-959c-e1e1deb16cae",
   "metadata": {},
   "source": [
    "## Textual problem statements were converted into numerical representations using TF-IDF vectorization. Unigrams and bigrams were used to capture both individual keywords and short algorithmic phrases. Stopword removal and vocabulary size limitation were applied to reduce noise and dimensionality while preserving discriminative information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
